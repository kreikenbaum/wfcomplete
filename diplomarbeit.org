#+TITLE: Selective Cover Traffic
#+TODO: KEYWORDS WRITE CHECK | EVA DANIEL FINAL
#+TODO: RECHECK | EVA-AGAIN DANIEL FINAL
#+TODO: WAIT | APPENDIX_DONE WAIT_FINISH
\pagenumbering{roman}
\listoffigures
\listoftables
* Configuration							    :ARCHIVE:
#+LATEX_CLASS: scrreprt
#+LATEX_CLASS_OPTIONS: [a4paper,10pt]
#+LATEX_HEADER: \usepackage{adjustbox}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{numprint}
#+LATEX_HEADER: \usepackage{pgf}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \restylefloat{table}
#+LATEX_HEADER: \setlongtables
#+LATEX_HEADER: \npdecimalsign{.}
#+LATEX_HEADER: \nprounddigits{2}
#+LATEX_HEADER: \npthousandthpartsep{}
#+LATEX_HEADER: \makeindex
#+LATEX_HEADER: \renewcommand*{\maketitle}{\thispagestyle{empty}
#+LATEX_HEADER:
#+LATEX_HEADER: \hspace{20cm}
#+LATEX_HEADER: \vspace{-2cm}
#+LATEX_HEADER:
#+LATEX_HEADER: \begin{figure} \hspace{11cm}
#+LATEX_HEADER: \includegraphics[width=3.2 cm]{pictures/HU_Logo}
#+LATEX_HEADER: \end{figure}
#+LATEX_HEADER:
#+LATEX_HEADER: \begin{center}
#+LATEX_HEADER:   \vspace{0.1 cm} % WAR: \vspace{0.5 cm}
#+LATEX_HEADER:   \huge{\bf Defending against Tor Website Fingerprinting with Selective Cover Traffic} \\ % Hier fuegen Sie den Titel Ihrer Arbeit ein.
#+LATEX_HEADER:   \vspace{1.1cm} % WAR: \vspace{1.5cm}
#+LATEX_HEADER:   \LARGE  Diplomarbeit \\ % Geben Sie anstelle der Punkte an, ob es sich um eine
#+LATEX_HEADER:                 % Diplomarbeit, eine Masterarbeit oder eine Bachelorarbeit handelt.
#+LATEX_HEADER:   \vspace{1cm}
#+LATEX_HEADER:   \Large zur Erlangung des akademischen Grades \\
#+LATEX_HEADER:   Diplominformatiker \\ % Bitte tragen Sie hier anstelle der Punkte ein:
#+LATEX_HEADER:          % Diplominformatiker(in),
#+LATEX_HEADER:          % Bachelor of Arts (B. A.),
#+LATEX_HEADER:          % Bachelor of Science (B. Sc.),
#+LATEX_HEADER:          % Master of Education (M. Ed.) oder
#+LATEX_HEADER:          % Master of Science (M. Sc.).
#+LATEX_HEADER:   \vspace{2cm}
#+LATEX_HEADER:   {\large
#+LATEX_HEADER:     \bf{
#+LATEX_HEADER:       \scshape
#+LATEX_HEADER:       Humboldt-Universit\"at zu Berlin \\
#+LATEX_HEADER:       Mathematisch-Naturwissenschaftliche Fakult\"at II \\
#+LATEX_HEADER:       Institut f\"ur Informatik\\
#+LATEX_HEADER:     }
#+LATEX_HEADER:   }
#+LATEX_HEADER:   % \normalfont
#+LATEX_HEADER: \end{center}
#+LATEX_HEADER: \vspace {1.9 cm}% gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte % mkreik <2016-07-11 Mo>: war {5 cm}
#+LATEX_HEADER: %{3.2 cm} bei Verwendung von scrreprt, gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte
#+LATEX_HEADER: {\large
#+LATEX_HEADER:   \begin{tabular}{llll}
#+LATEX_HEADER:     eingereicht von:    & Michael Kreikenbaum && \\ % Bitte Vor- und Nachnamen anstelle der Punkte eintragen.
#+LATEX_HEADER:     geboren am:         & 13.09.1981 && \\
#+LATEX_HEADER:     in:                 & Northeim && \\
#+LATEX_HEADER:     &&&\\
#+LATEX_HEADER:     Gutachter:          & Prof. Dr. Konrad Rieck (Universität Braunschweig) && \\
#+LATEX_HEADER: 		        & Prof. Dr. Marius Kloft && \\% Bitte Namen der Gutachter(innen) anstelle der Punkte eintragen
#+LATEX_HEADER: 				 % bei zwei männlichen Gutachtern kann das (innen) weggestrichen werden
#+LATEX_HEADER:     &&&\\
#+LATEX_HEADER:     eingereicht am:     & \dots\dots \\ % Bitte lassen Sie
#+LATEX_HEADER:                                     % diese beiden Felder leer.
#+LATEX_HEADER:                                     % Loeschen Sie ggf. das letzte Feld, wenn
#+LATEX_HEADER:                                     % Sie Ihre Arbeit laut Pruefungsordnung nicht
#+LATEX_HEADER:                                     % verteidigen muessen.
#+LATEX_HEADER:   \end{tabular}
#+LATEX_HEADER: }}
#+OPTIONS: H:6
* Introduction
#+BEGIN_LaTeX
  \pagenumbering{arabic}
#+END_LaTeX
  #+INDEX: Tor
  #+INDEX: trace
  #+INDEX: website fingerprinting
  In the wake of both the Snowden revelations in the western world,
  and increased internet censorship in countries such as Iran,
  Saudi-Arabia, and China\cite{china}, more and more
  Internet users search for ways to keep online communication and web
  browsing both private and free of censorship.

  The /Tor/ project\cite{tor-design} provides this. It protects
  whistleblowers, journalists, the people in oppressive
  regimes\cite{jardine2016tor}, even the military, and regular
  internet users, against e.g.\space{}nation-states or businesses which want
  to follow user's online steps. It routes encrypted data traffic via
  intermediaries, obscuring who connects to whom.

  # NO reflow here!!!
  While basic Tor acts as a proxy for any kind of TCP traffic, web
  browsing with Tor is user-friendly\cite{usability:weis2006}: you
  just need to
  \href{https://www.torproject.org/download/download-easy.html.en}{download the Tor Browser Bundle}. It connects automatically to the Tor
  network to cloak the client's web traffic.  \\
  # NO reflow here!!!


  As has often been the case with anonymity and privacy, several
  parties try to attack Tor's protection. One mass-surveillance type
  of attack that can be carried out passively with low-level
  technology is /website fingerprinting/: The time and size of users'
  data packets (called /traces/) are recorded. See Figure
  \ref{fig:traces}. This recording is compared to previously recorded
  traces of known sites. While older attacks
  (\cite{ccsw09-fingerprinting}, \cite{Liberatore:2006}) just compared
  single packet sizes, possibly by hand, newer attacks
  (\cite{panchenko}, \cite{panchenko2}, \cite{realistic}) use machine
  learning to classify traces, achieving high accuracy rates under
  laboratory conditions.
#+BEGIN_LaTeX
\begin{figure}[htbp]
\includegraphics[width=0.12\textwidth]{./pictures/craigslist_org@1445352269.png}
\includegraphics[width=0.12\textwidth]{./pictures/craigslist_org@1445585277.png}
\includegraphics[width=0.12\textwidth]{./pictures/craigslist_org@1445486337.png}\includegraphics[width=0.12\textwidth]{./pictures/craigslist_org@1445527033.png}\includegraphics[width=0.12 \textwidth]{./pictures/facebook_com@1445350531.png}
\includegraphics[width=0.12 \textwidth]{./pictures/facebook_com@1445422155.png}
\includegraphics[width=0.12 \textwidth]{./pictures/facebook_com@1445425799.png}
\includegraphics[width=0.12 \textwidth]{./pictures/facebook_com@1445429729.png}
\caption[Web trace data visualized]{Web trace data visualized. Box height signifies amount of data, width the duration until the next packet. The left 4 are for \url{http://craigslist.org}, the right for \url{http://facebook.com}.
While some similarity can be seen for each group, the "within-group" differences are quite big between each group's traces as well.}
\label{fig:traces}
\end{figure}
#+END_LaTeX

  Web fingerprinting effectively deanonymizes the traffic that users
  thought secure, exposing for example a dissident to his nation
  state, nullifying this part of Tor's protection. To protect against
  this, most early attacks (\cite{Wagner96analysisof}, \cite{hintz02},
  \cite{ssl-traffic-analysis}) also proposed defenses. These evolved
  from /specific defenses/, f.ex. packet-size-altering methods
  (\cite{httpos}, \cite{morphing09}) to /general defenses/, which
  transform groups of web retrievals so that all members look the
  same.

  At the start of the thesis, there existed mostly deterministic
  defenses with high overhead (f.ex. over 220% bandwidth, and 300%
  time\cite{a-systematic}). During the course of this thesis, the
  stochastic defenses of \cite{wang2015walkie} and \cite{wtfpad},
  with much lower overhead, were developed. This validates a
  stochastic approach, yet improvements seem possible in two areas:
  (1) ease of installation, and configurability, and (2) more-closely
  fitting cover traffic generation.

  Ad 1: \cite{wang2015walkie} alters the Firefox binary, while the
  current version of \cite{wtfpad} needed much manual adjustment in
  our attempts.

  Ad 2: \cite{wang2015walkie} uses either a normal, or lognormal
  distribution, not adjusting to HTTP-specifics, while \cite{wtfpad}
  samples packets at the network layer. It aims at hiding that traffic
  occurs, as it derives its basic mechanism from \cite{ShWa-Timing06}.
** Thesis Contribution
   This thesis presents and tests a new defense against website
   fingerprinting. This new defense mimics HTTP\cite{rfc7230}-shaped
   cover traffic: Each web page retrieval is augmented by
   stochastically-drawn dummy HTTP traffic\cite{newtrafficmodel}. This
   could optimize the protection offered for given bandwidth
   overhead. It is implemented in a browser extension, which makes the
   defense easier to install, configure, and maintain.
** Thesis Structure
   The following chapters try to solve the question whether the new
   defense works more effectively than existing ones.

   Chapter [[#ch2-background]] provides basic background for the IT-savvy
   who have not yet encountered Tor, machine learning, or website
   fingerprinting. For the Tor network, we treat its basic structure
   and why website fingerprinting might be a credible threat. Machine
   learning basic steps and algorithms are briefly skimmed. Finally,
   website fingerprinting on Tor is presented. These parts can safely
   be skipped given previous knowledge.

   The defense's why and how (motivation and design) is described in
   chapter [[#ch3-newdefense]]. This also describes the bloom sort data
   structure for stochastically saving object sizes.

   Chapter [[#ch4-evaluation]] evaluates the defense. It first describes
   the data-gathering process. Next, the website fingerprinting
   attacks of \cite{panchenko2}, and \cite{ccsw09-fingerprinting} are
   validated on defenseless data. This is followed by the evaluation
   on data with cloaking.

   These results are discussed and compared to literature results of
   \cite{wang2015walkie} and \cite{wtfpad} in chapter [[#ch5-discussion]].

   Chapter [[#ch6-conclusion]] summarizes the results, shows a path to
   implementation, with both included and additional further work.
* Background
  :PROPERTIES:
  :CUSTOM_ID: ch2-background
  :END:
  Understanding and countering website fingerprinting is helped by
  knowledge of [[#sub2-tor][the Tor network]], [[file:docs/master.bib::tcpdump8-manual][machine-learning basics]], and [[#sub2-wf][previous
  attacks and defenses]].
** The Tor Network
   :PROPERTIES:
   :CUSTOM_ID: sub2-tor
   :END:
   #+INDEX: onion router
   #+INDEX: onion proxy
   #+INDEX: Tor!onion router
   #+INDEX: Tor!onion proxy
   #+INDEX: Tor!the onion router
   #+CAPTION: \href{https://www.torproject.org/about/overview.html.en}{Connection through the Tor network}.
   #+NAME: fig:tor-network
   #+ATTR_LATEX: :float wrap :width 0.38\textwidth :placement {r}{0.4\textwidth}
   [[./pictures/htw2.png]]

   The Tor\cite{tor-design} network uses a semi-distributed
   infrastructure: Volunteer-run /onion routers/ pass the messages,
   while their structure is provided by fixed /directory servers/. A
   path through the onion routers is negotiated by the /onion proxy/,
   a SOCKS\cite{rfc1928}-TCP proxy which most often runs on the client
   computer.

   To initialize a connection, the onion proxy selects three
   globally-distributed hops. It makes a connection to the first,
   establishes encryption, asks the first hop to make a connection to
   the second, sets up encryption to this, and from there to the
   third. The third hop establishes a connection to its destination.

   Each message is encrypted three times using same-length encryption
   and sent along this path. The first router decrypts the first layer,
   and so on, like layers of an onion. This explains Tor's name /the
   onion router/.

   As a result of this setup, each hop can only see its direct
   neighbors along the path. Even if one hop of a three-hop setup is
   compromised, directly linking source and destination becomes pretty
   hard.
** Machine Learning
   #+INDEX: machine learning
   #+INDEX: ML
   The term /machine learning/ (short: ML) consists of the two parts
   "machine" and "learning". In this context, machine refers to a
   computing machine[\sect1]\cite{turing1936a}, while learning here means
   to improve prediction given training data
   \cite[sec.1.4.0]{duda}. In the words of Tom
   Mitchell\cite[sec.1.1]{mitchell}
     #+BEGIN_QUOTE
A computer program is said to *learn* from experience /E/ with
respect to some class of tasks /T/ and performance measure /P/, if
its performance at tasks in /T/, as measured by /P/, improves with
experience /E/.
     #+END_QUOTE

     Machine learning can conceptually be split into three steps:
     [[#ml-preprocess][preprocessing]], [[#ml-features][feature extraction]] and [[#ml-class][classification]][fn::Some
     authors, e.g. \cite{meffert}, adds an additional
     /Merkmalsreduktion/ (feature reduction) part after
     /Merkmalsextraktion/ (feature extraction).] The first step
     standardizes and cleans input data, the second transforms the raw
     input data --- in our case, website retrieval traces[fn::in
     =pcap= format] --- into characteristics --- in our case, numbers
     for f.ex. the number of outgoing packets. The third step groups these
     characteristics into categories.

     A last section details [[#ml-measure][measures to evaluate machine learning
     performance]].
*** Preprocessing
    :PROPERTIES:
    :CUSTOM_ID: ml-preprocess
    :END:
    #+INDEX: preprocessing
    #+INDEX: machine learning!preprocessing
    The raw data often needs to be adjusted. F.ex. images need to
    have their light level normalized\cite[sec.1.2.]{duda}. In our
    case, several packets of our own capture were removed,
    f.ex. TCP-ACKs, and either all traffic except to the bridge (see
    [[#capture][Capture]]), if used, or traffic to the cover traffic server if no
    bridge was used.[fn:: see code [[#1site_desc][=one_site=]] (filter), [[#7777][=7777.sh=]]
    (server), [[#counter][=counter.py=]]]

    The resultant intermediate data are tuples of =(packet size,
    timing)=, with positive/negative marking outgoing/incoming
    packets respectively.[fn::The assignment of positive/negative to
    incoming and outgoing data is dependent on author, see section
    [[#wf-original]].]
*** Feature Extraction
    :PROPERTIES:
    :CUSTOM_ID: ml-features
    :END:
    #+INDEX: feature extraction
    #+INDEX: machine learning!feature extraction
    Feature extraction\cite[sec.1.3.1]{duda} transforms the
    preprocessed raw data into features/characteristics suitable for
    classification. For this, it uses domain-specific knowledge. In
    website fingerprinting, among others the number and bytes of
    both incoming and outgoing packets are counted, for example.

    While the boundary of feature extraction to classification is
    "somewhat arbitrary"\cite[sec.1.3.1]{duda}, feature extraction
    deals with the, well, extraction of characteristics from the
    underlying data.
*** Classification
    :PROPERTIES:
    :CUSTOM_ID: ml-class
    :END:
    #+INDEX: classification
    #+INDEX: machine learning!classification
    Once the features' values are extracted, instances can be
    assigned[fn::Here, we deal only with classification. Another
    application is regression, where a real-valued function is
    estimated.] to a class[fn::some classifiers also allow the
    computation of class probabilities, etc].

    In website fingerprinting, each instance is a numerical input
    vector, which can be directly used by many classifiers. From
    these, most classifiers, such as [[*Support Vector Machines][support vector machines]], form a
    model from which further input data can be classified. Others,
    such as [[*K-Nearest-Neighbor-Classifier][k-Nearest-Neighbors]] classify directly without an
    intermediary model.
*** Measuring Performance
    :PROPERTIES:
    :CUSTOM_ID: ml-measure
    :END:
    #+INDEX: Accuracy (acc)
    #+INDEX: Area Under Curve
    #+INDEX: AUC
    #+INDEX: AUC$_{0.01}$
    #+INDEX: AUC!bounded
    #+INDEX: confusion matrix
    #+INDEX: False Positive Rate
    #+INDEX: fpr
    #+INDEX: Receiver Operating Characteristic curve
    #+INDEX: ROC curve
    #+INDEX: True Positive Rate
    #+INDEX: tpr
    To evaluate website fingerprinting attacks and defenses, their
    success needs to be measured.[fn::this section's definitions
    follow \cite{powers}] Starting with binary classification, a
    /confusion matrix/ helps to illustrate the different cases that
    can occur. Each instance is categorized by its real and
    predicted class --- in website fingerprinting, whether it /is/ a
    sensitive website, and whether it is /classified/ as such. See
    Table [[tab:confusion_matrix]].

    #+CAPTION: Confusion matrix. Correctly classified cases are in bold.
    #+NAME: tab:confusion_matrix
    #+ATTR_LATEX: :align r|l l
    |             | real 1                | real 2                |
    |-------------+-----------------------+-----------------------|
    | predicted 1 | *True Positives (TP)* | False Positives (FP)  |
    | predicted 2 | False Negatives (FN)  | *True Negatives (TN)* |

    From these absolute values, various metrics can be derived. The
    main metrics used in website fingerprinting literature are
    /Accuracy/ (short: acc)[fn::accuracy is mostly used in the
    closed-world case], and /True/ and /False Positive Rate/ (short:
    tpr and fpr)[fn::tpr and fpr are mostly used in the open-world
    case]. These are defined as

    #+ATTR_LATEX: :align r c l
    | True Positive Rate  | := | $TP / (TP + FN)$                  |
    | False Positive Rate | := | $FP / (FP + TN)$                  |
    | Accuracy            | := | $(TP + TN) / (TP + FP + FN + TN)$ |

    To show the classifier strictness tradeoff, a /Receiver
    Operating Characteristic Curve/ (short: ROC-Curve) can be used.
    This diagram contrasts classifier tpr vs fpr, see Figure
    [[fig:roc-example]]. The /area under/ the /curve/ (short: AUC) can
    be measured. The closer this value is to 1, the better. If one
    is mainly interested in low fpr, the leftmost section of the
    ROC-curve is of particular interest. The area under the curve
    bounded up to a fpr value of 0.01 is denoted AUC_{0.01}.

    #+CAPTION[ROC curve example]: Example Receiver Operating Characteristic (ROC) curve. Source: \cite[sec.11.18.8]{scikit-user-guide}.
    #+ATTR_LATEX: :width 0.4\textwidth
    #+NAME: fig:roc-example
    [[./pictures/plot_roc.png]]
** Machine Learning Algorithms
   :PROPERTIES:
   :CUSTOM_ID: sub2-ml
   :END:
   

     - steps\cite{rieckdiss}
       - preprocessing
       - feature extractions
       - classification
     - algorithms in classification (?)
       - todo: ask kloft via mitarbeiter
** Tor Website Fingerprinting
   :PROPERTIES:
   :CUSTOM_ID: sub2-wf
   :END:
   As all traffic analysis\cite{introta}, website fingerprinting is
   concerned only with message meta-data: who sends how much to
   whom. It assumes that the system itself is computationally
   secure\cite{applied96}: there are not enough resources, time, or
   data to break it. Thus, traffic analysis tries to circumvent the
   system, by analysing traffic patterns, as this can provide much
   useful information\cite{applied96}.

   Anyone who can see the data stream can attempt website
   fingerprinting, without anyone realising it. They simply need to
   capture the data stream using f.ex. the
   =tcpdump=\cite{tcpdump8-manual} tool.

   

- introduction into attack scenario for Tor Website Fingerprinting
- discussion of related approaches used to evaluate your approach (e.g. Panchenko,
Hermann)
- discussion of state-of-the art defenses and drawbacks of these techniques
- very brief description of other related approaches

- Tor's built-in wf defenses
  - fixed data cell size
  - increased latency through routes
  - multiplexes data
* Novel Defense
  :PROPERTIES:
  :CUSTOM_ID: ch3-newdefense
  :END:
* Evaluation
  :PROPERTIES:
  :CUSTOM_ID: ch4-evaluation
  :END:

* Discussion
  :PROPERTIES:
  :CUSTOM_ID: ch5-discussion
  :END:

* Conclusion
  :PROPERTIES:
  :CUSTOM_ID: ch6-conclusion
  :END:
\appendix
\part{Appendix}
* appendices (begin above this headline; this is for searching)     :ARCHIVE:
  above, as in this section cuts it out (due to ARCHIVE tag)
* Appendices
\bibliography{docs/master}
\bibliographystyle{plain}
\input{diplomarbeit.ind}
* END: /above/ this headline are INDEX, and BIBLIOGRAPHY, etc       :ARCHIVE:
